library(ggplot2)
library(dplyr)
library(gridExtra)
library(grid)
library(matrixStats)
library(RColorBrewer)
global<-read.csv('D/Studies/Research/Dataset - Kaggle/LeagueofLegends.csv',sep=',')
any(is.na(global))
##Number of games per `League` and `Year`
```{r}
g1<-global %>%
group_by(League, Season, Year) %>% summarise(number=n()) %>%
ggplot(aes(x=Year,y=number,fill=League)) +
geom_histogram(stat='identity',position='stack') +
scale_fill_manual(values=c("#3B9AB2", "#78B7C5", "#EBCC2A", "#E1AF00", "#F21A00","#9A8822", "#F5CDB4", "#F8AFA8","#713E5A","#63A375","#EDC79B","#D57A66","#CA6680","#48E5C2","#A1E8CC")) +
theme(legend.position='none')  + xlab('') + ylab('number of games')
g2<-global %>%
group_by(League) %>% summarise(number=n()) %>%
ggplot(aes(x=reorder(League,-number),y=number,fill=League)) +
geom_histogram(stat='identity') +
scale_fill_manual(values=c("#3B9AB2", "#78B7C5", "#EBCC2A", "#E1AF00", "#F21A00","#9A8822", "#F5CDB4", "#F8AFA8","#713E5A","#63A375","#EDC79B","#D57A66","#CA6680","#48E5C2","#A1E8CC")) +
theme(legend.position='top',axis.text.x = element_text(angle=45, hjust=1),legend.text=element_text(size=8),legend.key.size = unit(.3, "cm"))  + xlab('') + ylab('number of games')
grid.arrange(g1,g2,ncol=2)
g1
g1<-global %>%
group_by(League, Season, Year) %>% summarise(number=n()) %>%
ggplot(aes(x=Year,y=number,fill=League)) +
geom_histogram(stat='identity',position='stack') +
scale_fill_manual(values=c("#3B9AB2", "#78B7C5", "#EBCC2A", "#E1AF00", "#F21A00","#9A8822", "#F5CDB4", "#F8AFA8","#713E5A","#63A375","#EDC79B","#D57A66","#CA6680","#48E5C2","#A1E8CC")) +
theme(legend.position='none')  + xlab('') + ylab('number of games')
g1
global<-read.csv('D/Studies/Research/Dataset - Kaggle/LeagueofLegends.csv',sep=',')
global<-read.csv('D:/Studies/Research/Dataset - Kaggle/LeagueofLegends.csv',sep=',')
any(is.na(global))
##Number of games per `League` and `Year`
```{r}
g1<-global %>%
group_by(League, Season, Year) %>% summarise(number=n()) %>%
ggplot(aes(x=Year,y=number,fill=League)) +
geom_histogram(stat='identity',position='stack') +
scale_fill_manual(values=c("#3B9AB2", "#78B7C5", "#EBCC2A", "#E1AF00", "#F21A00","#9A8822", "#F5CDB4", "#F8AFA8","#713E5A","#63A375","#EDC79B","#D57A66","#CA6680","#48E5C2","#A1E8CC")) +
theme(legend.position='none')  + xlab('') + ylab('number of games')
g1
library(ggplot2)
library(dplyr)
library(gridExtra)
library(grid)
library(matrixStats)
library(RColorBrewer)
global<-read.csv('C:/Users/Kevin/Desktop/Sem 4/Research Dataset/LOL/LeagueofLegends.csv',sep=',')
any(is.na(global))
library(tidyverse)
install.packages("tidyverse")
global<-read.csv('D:/Studies/Research/Dataset - Kaggle/bans.csv',sep=',')
global<-read.csv('D:/Studies/Research/Dataset - Kaggle/bans.csv',sep=',')
any(is.na(global))
glimpse(global)
global<-read.csv('D:/Studies/Research/Dataset - Kaggle/bans.csv',sep=',')
any(is.na(global))
glimpse(global)
glimpse(global)
any(is.na(global))
install.packages(c("tm", "wordcloud", "SnowballC"))
install.packages (“RColorBrewer”)
install.packages("RColorBrewer")
global=data.frame(global)
global.Corpus=Corpus(VectorSource(global$ban_1))
global.Corpus=Corpus(VectorSource(global$ban_1))
library(tm)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
global<-read.csv('D:/Studies/Research/Dataset - Kaggle/bans.csv',sep=',')
any(is.na(global))
glimpse(global)
global=data.frame(global)
global.Corpus=Corpus(VectorSource(global$ban_1))
global.Clean<-tm_map(global.Corpus, PlainTextDocument
wordcloud(global.Clean,max.words = 200,random.color = TRUE,random.order=FALSE)
global.Corpus=Corpus(VectorSource(global$ban_1))
global.Clean<-tm_map(global.Corpus, PlainTextDocument
global.Clean<-tm_map(global.Clean,removeNumbers)
global.Clean<-tm_map(global.Clean,removeWords,stopwords("english"))
global.Clean<-tm_map(global.Clean,removePunctuation)
global.Clean<-tm_map(global.Clean,stripWhitespace)
global.Clean<-tm_map(global.Clean,stemDocument)
wordcloud(global.Clean,max.words = 200,random.color = TRUE,random.order=FALSE)
global.Clean<-tm_map(global.Corpus, PlainTextDocument
global.Clean<-tm_map(global.Clean,removeNumbers)
global.Clean<-tm_map(global.Corpus, PlainTextDocument)
global.Clean<-tm_map(global.Corpus,tolower)
global.Clean<-tm_map(global.Clean,removeNumbers)
global.Clean<-tm_map(global.Clean,removeWords,stopwords("english"))
global.Clean<-tm_map(global.Clean,removePunctuation)
global.Clean<-tm_map(global.Clean,stripWhitespace)
global.Corpus=Corpus(global$ban_1)
global.Clean<-tm_map(global.Corpus, PlainTextDocument)
global.Corpus=Corpus(global$ban_1)
global.Corpus=Corpus(VectorSource(global$ban_1,global$ban_2))
global.df
nrow(global)
paste(unlist(global$ban_1), collapse =" ")
x=paste(unlist(global$ban_1), collapse =" ")
global.Corpus=Corpus(VectorSource(x))
global.Clean<-tm_map(global.Corpus, PlainTextDocument)
global.Clean<-tm_map(global.Corpus,tolower)
global.Clean<-tm_map(global.Clean,removeNumbers)
global.Clean<-tm_map(global.Clean,removeWords,stopwords("english"))
global.Clean<-tm_map(global.Clean,removePunctuation)
global.Clean<-tm_map(global.Clean,stripWhitespace)
global.Clean<-tm_map(global.Clean,stemDocument)
wordcloud(global.Clean,max.words = 200,random.color = TRUE,random.order=FALSE)
wordcloud(global.Clean,max.words = 200,random.color = TRUE,random.order=FALSE)
global.Clean<-tm_map(global.Corpus, PlainTextDocument)
global.Clean<-tm_map(global.Clean,removeNumbers)
global.Clean<-tm_map(global.Clean,removeWords,stopwords("english"))
global.Clean<-tm_map(global.Clean,removePunctuation)
global.Clean<-tm_map(global.Clean,stripWhitespace)
global.Clean<-tm_map(global.Clean,stemDocument)
wordcloud(global.Clean,max.words = 200,random.color = TRUE,random.order=FALSE)
x=paste(unlist(global$ban_1,global$ban_2), collapse =" ")
global.Corpus=Corpus(VectorSource(x))
global.Clean<-tm_map(global.Corpus, PlainTextDocument)
global.Clean<-tm_map(global.Corpus,tolower)
global.Clean<-tm_map(global.Clean,removeNumbers)
global.Clean<-tm_map(global.Clean,removeWords,stopwords("english"))
global.Clean<-tm_map(global.Clean,removePunctuation)
global.Clean<-tm_map(global.Clean,stripWhitespace)
global.Clean<-tm_map(global.Clean,stemDocument)
wordcloud(global.Clean,max.words = 200,random.color = TRUE,random.order=FALSE)
x
x=paste(unlist(global$ban_1), collapse =" ")
x
x=paste(unlist(global$ban_1,global$ban_2), collapse =" ")
x
wordcloud(global.Clean,max.words = 300,random.color = TRUE,random.order=FALSE)
wordcloud(global.Clean,max.words = 300,random.color = TRUE,random.order=FALSE)
global<-read.csv('C:/Users/Kevin/Desktop/Sem 4/Research Dataset/LOL/bans.csv',sep=',')
any(is.na(global))
View(global)
ed=as.data.frame(global)
View(ed)
tbl <- with(ed, table(ban_1))
View(tbl)
tbl1=data.frame(tbl)
tbl1$freq
nrow(tbl1$ban1)
tbl1$Freq
View(tbl1$Freq>90)
View(tbl)
tbl1=data.frame(tbl)
tbl <- with(ed, table(c(ban1,ban2)))
View(tbl)
View(ed)
tbl <- with(ed, table(ban_1))
View(tbl)
tbl <- with(ed, table(ban_1))
tbl <- with(ed, table(ban_1))
tbl1=data.frame(tbl)
View(tbl)
tbl <- with(ed, table(ban_1))
View(tbl)
tbl <- with(ed, table(ban_1))
View(tbl)
tblx <- with(ed, table(ban_2))
View(tblx)
global<-read.csv('C:/Users/Kevin/Desktop/Sem 4/Research Dataset/LOL/bans.csv',sep=',')
any(is.na(global))
View(global)
View(ed)
tbl <- with(ed, table(ban_1))
View(tbl)
global<-read.csv('C:/Users/Kevin/Desktop/Sem 4/Research Dataset/LOL/bans.csv',sep=',')
any(is.na(global))
View(global)
ed=as.data.frame(global)
View(ed)
x=paste(unlist(global$ban_1), collapse =" ")
x=paste(unlist(global$ban_1), collapse =" ")
x
x=x+paste(unlist(global$ban_2), collapse =" ")
g=unlist(global$ban_1)
g
view(g)
View(g)
allBan=paste(ban1,ban2,ban3,ban4,ban5,collapse =" ")
ban1=unlist(global$ban_1)
ban2=unlist(global$ban_2)
ban3=unlist(global$ban_3)
ban4=unlist(global$ban_4)
ban5=unlist(global$ban_5)
allBan=paste(ban1,ban2,ban3,ban4,ban5,collapse =" ")
View(allBan)
allBan
global.Corpus=Corpus(VectorSource(allBan))
global.Clean<-tm_map(global.Corpus, PlainTextDocument)
global.Clean<-tm_map(global.Corpus,tolower)
global.Clean<-tm_map(global.Clean,removeNumbers)
global.Clean<-tm_map(global.Clean,removeWords,stopwords("english"))
global.Clean<-tm_map(global.Clean,removePunctuation)
global.Clean<-tm_map(global.Clean,stripWhitespace)
global.Clean<-tm_map(global.Clean,stemDocument)
wordcloud(global.Clean,max.words = 300,random.color = TRUE,random.order=FALSE)
words<-strsplit(allBan," ")
#Calculate word frequencies
words.freq<-table(unlist(words));
words.freq
View(words.freq)
#Calculate word frequencies
words.freq<-table(words);
View(words.freq)
#Calculate word frequencies
wordfreq<-table(unlist(words));
View(wordsfreq)
#Calculate word frequencies
wordfreq<-table(unlist(words));
View(wordsfreq)
View(wordfreq)
#tudentdata[studentdata$Drink == 'water',]
wordfreq[wordfreq$Freq <10]
#tudentdata[studentdata$Drink == 'water',]
wordfreq[wordfreq$Freq <10,]
#tudentdata[studentdata$Drink == 'water',]
wordfreq=data.frame(wordfreq)
wordfreq[wordfreq$Freq <5]
wordfreq[wordfreq$Freq <5,]
View(res)
res=wordfreq[wordfreq$Freq <5,]
View(res)
global<-read.csv('D:/Studies/Research/Dataset - Kaggle/bans2.csv',sep=',')
any(is.na(global))
glimpse(global)
global=data.frame(global)
nrow(global)
ban1=unlist(global$ban_1)
ban2=unlist(global$ban_2)
ban3=unlist(global$ban_3)
ban4=unlist(global$ban_4)
ban5=unlist(global$ban_5)
allBan=paste(ban1,ban2,ban3,ban4,ban5,collapse =" ")
allBan
words<-strsplit(allBan," ")
#Calculate word frequencies
wordfreq<-table(unlist(words));
View(wordfreq)
allBan=paste(ban1,ban2,ban3,ban4,ban5,collapse =" ")
allBan
words<-strsplit(allBan," ")
#Calculate word frequencies
wordfreq<-table(unlist(words));
View(wordfreq)
res=wordfreq[wordfreq$Freq <5,]
View(res)
words<-strsplit(allBan," ")
#Calculate word frequencies
wordfreq<-table(unlist(words));
View(wordfreq)
#tudentdata[studentdata$Drink == 'water',]
wordfreq=data.frame(wordfreq)
res=wordfreq[wordfreq$Freq <5,]
View(res)
View(wordfreq)
res=wordfreq[wordfreq$Freq >1000,]
View(res)
res=wordfreq[wordfreq$Freq >500,]
View(res)
plot(wordfreq$Var1,wordfreq$Freq)
library(ggplot2)
ggplot(wordfreq)
ggplot(wordfreq)
plot(wordfreq$Var1,wordfreq$Freq)
ggplot(wordfreq)
plot(wordfreq$Var1,wordfreq$Freq)
res=wordfreq[wordfreq$Freq >700,]
View(res)
ggplot(wordfreq)
barplot(wordfreq)
barplot(wordfreq)
barplot(words)
barplot(words)
barplot(table(unlist(words)))
View(res)
ban1=unlist(global$ban_1)
nrow(global)
allBan=paste(ban1,ban2,ban3,ban4,ban5,collapse =" ")
allBan
res=res[2:]
#tudentdata[studentdata$Drink == 'water',]
wordfreq=data.frame(wordfreq)
wordfreq
nrow(res)
nrow(wordfreq)
wordfreq=wordfreq[2:137,]
wordfreq
View(wordfreq)
#tudentdata[studentdata$Drink == 'water',]
wordfreq=data.frame(wordfreq)
View(wordfreq)
#Calculate word frequencies
wordfreq<-table(unlist(words));
#tudentdata[studentdata$Drink == 'water',]
wordfreq=data.frame(wordfreq)
View(wordfreq)
nrow(wordfreq)
wordfreq=wordfreq[2:137,]
nrow(wordfreq)
View(wordfreq)
res=wordfreq[wordfreq$Freq >700,]
plot(wordfreq$Var1,wordfreq$Freq)
ggplot(wordfreq)
barplot(table(unlist(words)))
barplot(wordfreq)
barplot(table(unlist(words)))
barplot(wordfreq)
barplot(table(wordfreq)
barplot(table(wordfreq))
barplot(table(wordfreq))
barplot(table(wordfreq))
barplot(wordfreq)
barplot(table(unlist(words)))
allBan=data.frame(allBan)
nrow(allBan)
View(words)
barplot(table(unlist(words)))
barplot(table(list(words)))
allBan=data.frame(allBan)
words<-strsplit(allBan," ")
#Calculate word frequencies
wordfreq<-table(unlist(words));
View(wordfreq)
wordfreq=data.frame(wordfreq)
View(wordfreq)
nrow(wordfreq)
wordfreq=wordfreq[2:137,]
View(wordfreq)
plot(wordfreq$Var1,wordfreq$Freq)
barplot(wordfreq)
barplot(50,wordfreq)
barplot(table(wordfreq))
barplot(table(res))
barplot(res)
barplot(res$Freq)
barplot(res$Freq,legend = rownames(counts))
barplot(res$Freq,legend = rownames(res))
barplot(res$Freq,legend = rownames(res$Var1))
barplot(res$Freq,legend = rownames(res$Var1))
res=wordfreq[wordfreq$Freq >1200,]
barplot(res$Freq)
barplot
help(barplot)
barplot(res$Freq,names.arg = res$Var1)
barplot(res$Freq,names.arg = res$Var1,par(las=2))
barplot(res$Freq,names.arg = res$Var1,par(las=1))
barplot(res$Freq,names.arg = res$Var1,par("cex.axis"))
barplot(res$Freq,names.arg = res$Var1,axes = TRUE)
barplot(res$Freq,names.arg = res$Var1,axes = FALSE)
barplot(res$Freq,names.arg = res$Var1,axisnames = TRUE)
barplot(res$Freq,names.arg = res$Var1,axisnames = FALSE)
barplot(res$Freq,names.arg = res$Var1)
barplot(res$Freq,names.arg = res$Var1,axis(las=2))
barplot(res$Freq,names.arg = res$Var1,las=1)
barplot(res$Freq,names.arg = res$Var1,las=1)
barplot(res$Freq,names.arg = res$Var1,las=1)
barplot(res$Freq,names.arg = res$Var1,las=2)
res=wordfreq[wordfreq$Freq >1000,]
barplot(res$Freq,names.arg = res$Var1,las=2)
View(res)
allBan=data.frame(allBan)
words<-strsplit(allBan," ")
#Calculate word frequencies
wordfreq<-table(unlist(words));
View(wordfreq)
View(wordfreq)
